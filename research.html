<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Blog</title>
  <link rel="stylesheet" href="styles.css">
</head>

<body>

  <header>
    <nav>
      <a href="index.html">Blog</a>
      <a href="learn.html" class="active">Learn</a>
      <button class="theme-toggle" aria-label="Toggle theme">
        <svg id="icon-sun" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
          <path
            d="M12 2.25a.75.75 0 01.75.75v2.25a.75.75 0 01-1.5 0V3a.75.75 0 01.75-.75zM7.5 12a4.5 4.5 0 114.5 4.5A4.5 4.5 0 017.5 12zM2.25 12a.75.75 0 01.75-.75h2.25a.75.75 0 010 1.5H3a.75.75 0 01-.75-.75zM12 18.75a.75.75 0 01.75.75v2.25a.75.75 0 01-1.5 0v-2.25a.75.75 0 01.75-.75zM18.75 12a.75.75 0 01.75-.75h2.25a.75.75 0 010 1.5h-2.25a.75.75 0 010 1.5h-2.25a.75.75 0 01-.75-.75zM5.636 5.636a.75.75 0 011.06 0l1.591 1.591a.75.75 0 01-1.06 1.06L5.637 6.697a.75.75 0 010-1.061zM15.713 15.713a.75.75 0 011.06 0l1.591 1.591a.75.75 0 01-1.06 1.06l-1.59-1.591a.75.75 0 010-1.06zM5.636 18.364a.75.75 0 010-1.06l1.591-1.591a.75.75 0 011.06 1.06L6.697 18.363a.75.75 0 01-1.06 0zM15.713 8.288a.75.75 0 010-1.06l1.591-1.591a.75.75 0 011.06 1.06l-1.59 1.591a.75.75 0 01-1.061 0z" />
        </svg>
        <svg id="icon-moon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" style="display: none;">
          <path
            d="M9.528 1.718a.75.75 0 01.162.819A8.97 8.97 0 009 6a9 9 0 009 9 8.97 8.97 0 003.463-.69.75.75 0 01.981.98 10.503 10.503 0 01-9.694 6.46c-5.799 0-10.5-4.701-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 01.818.162z" />
        </svg>
      </button>
    </nav>
  </header>

  <main>
    <h1>Thoughts on building AI things </h1>
    <p class="muted"> Notes that sparked ideas, books that taught me new technologies, projects that turned theory into
      practice,
      and research that added depth - all in one place, documenting how I learn, experiment, and apply ideas in real
      systems.
    </p>

    <menu class="menu-highlight">
      <a href="learn.html">Notes</a>
      <a href="books.html">Books</a>
      <a href="projects.html">Projects</a>
      <a href="research.html" aria-current="page">Research</a>
    </menu>

    <div class="divider"></div>

    <p>Exploring groundbreaking research, Interpreting findings accurately,
      Reviewing existing literature and Drawing informed conclusions</p>

    <div class="divider"></div>

    <h2>Recursive Language Models</h2>
    <p class="muted">Lowering memory consumption and increasing training speed of BERT by introducing two
      parameter-reduction
      techniques overcoming the GPU/TPU training limitations
    </p>

    <p class="repo">
      <a href="research/20260127_rlm.html">
        Read more
      </a>
    </p>

    <h2>Llama 3 Herd of Models</h2>
    <p class="muted">Set of advanced foundation models supporting multilinguality, coding, reasoning,
      and tool use, with up to 405B parameters. It rivals GPT-4 in performance, integrates image, video,
      and speech capabilities, and includes safety features via Llama Guard 3
    </p>

    <p class="repo">
      <a href="research/20260127_llama.html">
        Read more
      </a>
    </p>

    <h2>Attention Is All You Need!</h2>
    <p class="muted"> The Transformer network revolutionizes sequence transduction models by replacing
      conventional recurrent and convolutional structures, setting new benchmarks in various
      machine learning tasks
    </p>

    <p class="repo">
      <a href="research/20260127_attention.html">
        Read more
      </a>
    </p>

    <h2>BERT Pre-training of Deep Bidirectional Transformers for Language Understanding</h2>
    <p class="muted">Bidirectional Encoder Representations from Transformers designed to pre-train deep bidirectional
      representations from unlabelled text by jointly conditioning on both left and right context in all layers
    </p>

    <p class="repo">
      <a href="https://github.com/jaiganesh-vr">
        Read more
      </a>
    </p>

    <h2>ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</h2>
    <p class="muted">Lowering memory consumption and increasing training speed of BERT by introducing two
      parameter-reduction
      techniques overcoming the GPU/TPU training limitations
    </p>

    <p class="repo">
      <a href="https://github.com/jaiganesh-vr">
        Read more
      </a>
    </p>

    <div class="divider"></div>

    <footer class="site-footer">
      <a href="https://github.com/jaiganesh-vr" target="_blank">↗ Github</a>
      <a href="https://www.upwork.com/" target="_blank">↗ Upwork</a>
      <a href="https://www.linkedin.com/in/jaiganesh-vr/" target="_blank">↗ LinkedIn</a>
    </footer>

  </main>
  <script src="js/theme.js"></script>
</body>

</html>